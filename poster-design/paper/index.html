<!doctype html>
<html>
<head>
<title>neural audio: music information retrieval using deep neural networks</title>
<style type="text/css">
body{
	height:36in;
	width:48in;
	font-family:Avenir;
	position:relative;
	font-size:30pt;
}
header{
	text-align:center;
	width:100%;
	height:4in;
}
header img{
	position:absolute;
	max-height:3.5in;	
	max-width:3.5in;
	top:.5in;
}
header h1, header h2{
	margin-left:4.5in;
	margin-right:4.5in;
	font-weight:normal;
}
header h1{
	font-size:80pt;
}
header h2{
	font-size:60pt;
}
#LSUlogo{
	left:.5in;
}
#NSFlogo{
	right:.5in;
	top:0in;
}
section{
	width:15in;
	margin-left:.5in;
	margin-right:.5in;
	position:absolute;
	background-color:transparent !important;
}
section.first{
	left:.5in;
}
section.second{
	left:16in;
}
section.third{
	right:.5in;
}

section h1{
	font-size:60pt;
	font-weight:normal;
}

.neuralnet{
	background-color:#8ae234;
}
.genreID{
	background-color:#729fcf;
}
.instID{
	background-color:#fcaf3e;
}
.mir{
	background-color:#ad7fa8;
	color:#eeeeec;
}
section h1{
	width:100%;
	text-align:center;
}

#introduction{
	height:15in;
}
#neurnet{
	top:16in;
	height:20in;

}
</style>
</head>
<body>
<header>
	<img src="lsu.png" alt="Louisiana State University" id="LSUlogo">
	<h1>neural audio: music information retrieval using deep neural networks</h1>
	<h2>Grey Patterson (Linfield), Andrew Pfalz, Dr. Jesse Allison (LSU CCT)</h2>
	<img src="nsf.png" alt="National Science Foundation" id="NSFlogo">
</header>
<section class="poster first" id="introduction">
	<h1>introduction</h1>
	<div>
		<p>Neural networks are a form of <span class="neuralnet">machine learning</span> based off the functionality of the human brain. They consists of <span class="neuralnet">nodes</span> connected by <span class="neuralnet">weighted edges</span> - similar to the structure of neurons. Input goes in as floating-point numbers, and is propagated through the network from node to node along those edges.</p>
		<p>The outputs and inputs can be basically anything you want: all of the image-recognition features in Google and Apple Photos are powered by neural networks; Microsoft's Skype Translate feature uses neural networks to perform real-time translation; the DeepMind group used neural networks to create AlphaGo, the world's best Go player.</p>
	</div>
	<div>
		<p>To date, however, there has been very little use of this form of machine learning in the field of music information retrieval. Services like Pandora and Spotify provide algorithmic music detection, but their actual databases are assembled through human labor and data mining, respectively.</p>
		<p>Music is rich in information - from things like what key and time signature are being played in up to the sociocultural context in which the lyrics were written. Musicologists work to extract this information in meaningful ways, but there is far more music in the world than there are musicologists. Providing automated tools to ease their efforts could be of significant benefit.</p>
		<p>The field of <span class="mir">music information retrieval</span> exists to provide these tools, and they have: automated beat-detection is doable, and identifying the key can be done with some effort. More complex tasks, though, remain out of reach. There is no algorithm to identify the <span class="genreID">genre</span> of a piece, and no machine can identify which <span class="instID">instrument</span> is playing as easily as a human can.</p>
	</div>
</section>
<section class="neuralnet first" id="neurnet">
	<h1>neural networks</h1>
</section>
<section class="genreid second">
	<h1>genre identification</h1>
</section>
<section class="instid third">
	<h1>instrument identification</h1>
</section>
</body>
</html>